{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transfer learning / fine-tuning\n",
    "---\n",
    "\n",
    "This tutorial will guide you through the process of using transfer learning to learn an accurate image classifier from a relatively small number of training samples. Generally speaking, transfer learning refers to the process of leveraging the knowledge learned in one model for the training of another model.\n",
    "\n",
    "More specifically, the process involves taking an existing neural network which was previously trained to good performance on a larger dataset, and using it as the basis for a new model which leverages that previous network's accuracy for a new task. This method has become popular in recent years to improve the performance of a neural net trained on a small dataset; the intuition is that the new dataset may be too small to train to good performance by itself, but we know that most neural nets trained to learn image features often learn similar features anyway, especially at early layers where they are more generic (edge detectors, blobs, and so on).\n",
    "\n",
    "Transfer learning has been largely enabled by the open-sourcing of state-of-the-art models; for the top performing models in image classification tasks (like from ILSVRC), it is common practice now to not only publish the architecture, but to release the trained weights of the model as well. This lets amateurs use these top image classifiers to boost the performance of their own task-specific models.\n",
    "\n",
    "## Feature extraction vs. fine-tuning\n",
    "At one extreme, transfer learning can involve taking the pre-trained network and freezing the weights, and using one of its hidden layers (usually the last one) as a feature extractor, using those features as the input to a smaller neural net.\n",
    "\n",
    "At the other extreme, we start with the pre-trained network, but we allow some of the weights (usually the last layer or last few layers) to be modified. Another name for this procedure is called \"fine-tuning\" because we are slightly adjusting the pre-trained net's weights to the new task. We usually train such a network with a lower learning rate, since we expect the features are already relatively good and do not need to be changed too much.\n",
    "\n",
    "Sometimes, we do something in-between: Freeze just the early/generic layers, but fine-tune the later layers. Which strategy is best depends on the size of your dataset, the number of classes, and how much it resembles the dataset the previous model was trained on (and thus, whether it can benefit from the same learned feature extractors). A more detailed discussion of how to strategize can be found in [[1]](https://cs231n.github.io/transfer-learning/) and [[2]](https://sebastianruder.com/transfer-learning/).\n",
    "\n",
    "Procedure\n",
    "In this guide will go through the process of loading a state-of-the-art, 1000-class image classifier, VGG16 which won the ImageNet challenge in 2014, and using it as a fixed feature extractor to train a smaller custom classifier on our own images, although with very few code changes, you can try fine-tuning as well.\n",
    "\n",
    "We will first load VGG16 and remove its final layer, the 1000-class softmax classification layer specific to ImageNet, and replace it with a new classification layer for the classes we are training over. We will then freeze all the weights in the network except the new ones connecting to the new classification layer, and then train the new classification layer over our new dataset.\n",
    "\n",
    "We will also compare this method to training a small neural network from scratch on the new dataset, and as we shall see, it will dramatically improve our accuracy. We will do that part first.\n",
    "\n",
    "As our test subject, we'll use a dataset consisting of around 6000 images belonging to 97 classes, and train an image classifier with around 80% accuracy on it. It's worth noting that this strategy scales well to image sets where you may have even just a couple hundred or less images. Its performance will be lesser from a small number of samples (depending on classes) as usual, but still impressive considering the usual constraints."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "#if using Theano with GPU\n",
    "#os.environ[\"KERAS_BACKEND\"] = \"tensorflow\"\n",
    "\n",
    "import random\n",
    "import numpy as np\n",
    "import keras\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import imshow\n",
    "\n",
    "from PIL import Image\n",
    "from keras.preprocessing import image\n",
    "from keras.applications.imagenet_utils import preprocess_input\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Activation\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.models import Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Execute the code below if you want to download the Cats_And_Dogs dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!echo \"Downloading Cats_and_Dogs for image notebooks\"\n",
    "!curl -L -o cats_and_dogs.zip --progress-bar https://download.microsoft.com/download/3/E/1/3E1C3F21-ECDB-4869-8368-6DEBA77B919F/kagglecatsanddogs_5340.zip\n",
    "!unzip cats_and_dogs.zip\n",
    "!rm cats_and_dogs.zip\n",
    "!ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As I ran some tests, I discovered that there are two images that are corupted:\n",
    "*   PetImages/Dog/11702.jpg\n",
    "*   PetImages/Cat/666.jpg\n",
    "\n",
    "Let's remove those images from our dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files_to_remove = ['PetImages/Dog/11702.jpg', 'PetImages/Cat/666.jpg']\n",
    "try:\n",
    "    for file in files_to_remove:\n",
    "        os.remove(file)\n",
    "except FileNotFoundError as e:\n",
    "    print('The files were already removed: ', e)\n",
    "except Exception as e:\n",
    "    print('There was an unexpected error: ', e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating a list with all categories, according to the directories inside the Root path:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = 'PetImages'\n",
    "\n",
    "categories = [x[0] for x in os.walk(root) if x[0]][1:]\n",
    "categories = [c for c in categories]\n",
    "\n",
    "print(categories)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating a helper function, useful for pre-processing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper function to load image and return it and input vector\n",
    "def get_image(path):\n",
    "    img = image.load_img(path, target_size=(224, 224))\n",
    "    x = image.img_to_array(img).astype(np.uint8)\n",
    "    #x = np.expand_dims(x, axis=0)\n",
    "    #x = preprocess_input(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inserting all images inside a list:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "for c, category in enumerate(categories):\n",
    "    try:\n",
    "        images = [os.path.join(dp, f) for dp, dn, filenames \n",
    "                in os.walk(category) for f in filenames \n",
    "                if os.path.splitext(f)[1].lower() in ['.jpg','.png','.jpeg']]\n",
    "        for img_path in images:\n",
    "            x = get_image(img_path)\n",
    "            data.append({'x':np.array(x), 'y':c})\n",
    "    except Exception as e:\n",
    "        print(img_path)\n",
    "\n",
    "\n",
    "print(f'Variable size is: {sys.getsizeof(data)} bytes')\n",
    "# count the number of classes\n",
    "num_classes = len(categories)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Shuffling data, but keeping track of a reproducible seed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.Random(42).shuffle(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once shuffled, lets head to the **split** step.\n",
    "In this step we will consider the following:\n",
    "*   Training: 70% of the samples;\n",
    "*   Validation: 15% of the samples;\n",
    "*   Test: 15% of the samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_split = 0.7\n",
    "val_split = 0.15\n",
    "test_split = 0.15\n",
    "\n",
    "idx_val = int(tr_split * len(data))\n",
    "idx_test = int((tr_split + val_split) * len(data))\n",
    "train = data[:idx_val]\n",
    "val = data[idx_val:idx_test]\n",
    "test = data[idx_test:]\n",
    "\n",
    "del data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's perform the split into X (features) and y (labels) sets (*similar to **sklearn.train_test_split()***):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = np.array([t[\"x\"] for t in train]), [t[\"y\"] for t in train]\n",
    "X_val, y_val = np.array([t[\"x\"] for t in val]), [t[\"y\"] for t in val]\n",
    "X_test, y_test = np.array([t[\"x\"] for t in test]), [t[\"y\"] for t in test]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalizing the colors between 0 and 1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize data\n",
    "X_train = X_train.astype('float32') / 255\n",
    "X_val = X_val.astype('float32') / 255\n",
    "X_test = X_test.astype('float32') / 255\n",
    "\n",
    "# convert labels to one-hot vectors\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_val = keras.utils.to_categorical(y_val, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_tl_dio",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
